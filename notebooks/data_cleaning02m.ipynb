{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cfa1fd3b",
   "metadata": {},
   "source": [
    "# DATA CLEANING PROCEDURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bff3efd",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Loading the Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83813bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load datasets\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('submission.csv')\n",
    "columns_description = pd.read_csv('column_descriptions.csv')\n",
    "\n",
    "# Quick overview\n",
    "print(\"Train shape:\", train.shape)\n",
    "print(\"Test shape:\", test.shape)\n",
    "print(\"\\nTrain columns and types:\\n\", train.dtypes.head())\n",
    "train.head() # Display first few rows of the train dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bb6bc6",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Checking missing values\n",
    "\n",
    "We define a function which summarizes:\n",
    "* how many missing values each column has\n",
    "* what % of data is missing\n",
    "* only columns with missing values are shown\n",
    "* results are sorted from worst to best\n",
    "\n",
    "We check both Train and Test datasets, and merge the results for easy comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d494e286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to summarize missing values\n",
    "def missing_summary(df, dataset_name=\"Dataset\"):\n",
    "    total = df.isnull().sum()\n",
    "    percent = (total / len(df)) * 100\n",
    "    missing_table = pd.concat([total, percent], axis=1)\n",
    "    missing_table.columns = [f'Missing Values ({dataset_name})', f'% Missing ({dataset_name})']\n",
    "    missing_table = missing_table[missing_table[f'Missing Values ({dataset_name})'] > 0]\n",
    "    return missing_table.sort_values(f'% Missing ({dataset_name})', ascending=False)\n",
    "\n",
    "# Summarizing missing values for train and test\n",
    "missing_train = missing_summary(train, \"Train\")\n",
    "missing_test = missing_summary(test, \"Test\")\n",
    "\n",
    "# Merging both summaries together\n",
    "missing_values = missing_train.merge(missing_test, how='outer', left_index=True, right_index=True)\n",
    "\n",
    "# Sort by maximum % missing across Train and Test\n",
    "missing_values['Max % Missing'] = missing_values[\n",
    "    [col for col in missing_values.columns if '% Missing' in col]\n",
    "].max(axis=1)\n",
    "missing_values = missing_values.sort_values(by='Max % Missing', ascending=False)\n",
    "missing_values.drop(columns='Max % Missing', inplace=True)\n",
    "\n",
    "# Display the missing values table\n",
    "print(missing_values)\n",
    "\n",
    "# Visualizing missing values\n",
    "plt.figure(figsize=(12, 6))\n",
    "missing_values[\n",
    "    [col for col in missing_values.columns if '% Missing' in col]\n",
    "].plot(kind='bar', figsize=(14, 6))\n",
    "plt.title(\"Missing Values (%): Train vs Test\")\n",
    "plt.ylabel(\"Percentage Missing\")\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e2f5440",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Planning the Cleaning Strategy\n",
    "\n",
    "After analyzing the missing values, we decided cleaning actions based on two criteria:\n",
    "- percentage of missing values;\n",
    "- importance of each column for predicting player market value\n",
    "\n",
    "Actions applied:\n",
    "* DROP columns with too many missing values (>50%) -> if they are not critical \n",
    "* FILL missing values in numerical columns -> using median to avoid influence from outliers\n",
    "* FILL missing values in categorical columns -> with 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e659eacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to drop\n",
    "columns_to_drop = [\n",
    "    'player_traits', 'player_tags', 'club_loaned_from', 'nation_jersey_number', \n",
    "    'nation_position', 'goal_keeping_speed']\n",
    "\n",
    "# Numerical Columns to Fill with Median\n",
    "numerical_cols = [\n",
    "    'release_clause_eur', 'defending', 'dribbling', 'pace',\n",
    "    'passing', 'physic', 'shooting', 'wage_eur']\n",
    "# (Exclude club_jersey_number: not relevant)\n",
    "\n",
    "# Categorical Columns to Fill with 'Unknown'\n",
    "categorical_cols = [\n",
    "    'club_name', 'club_position', 'league_name', 'club_contract_valid_until']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "781cffc3",
   "metadata": {},
   "source": [
    "---\n",
    "# 4. Applying the Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "482e575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. DROP columns -> too many missing values + not critical for predicting market value\n",
    "train.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "test.drop(columns=columns_to_drop, inplace=True, errors='ignore')\n",
    "# Quick check : dropped columns\n",
    "print(\"Dropped columns from train:\", columns_to_drop)\n",
    "print(\"Dropped columns from test:\", columns_to_drop)\n",
    "\n",
    "# 2. FILL numerical columns -> with median\n",
    "for column in numerical_cols: \n",
    "    median_value = train[column].median()\n",
    "    train[column] = train[column].fillna(median_value)\n",
    "    test[column] = test[column].fillna(median_value)\n",
    "# Quick check: filled numerical columns\n",
    "print(\"Train numerical columns after filling:\", train[numerical_cols].isnull().sum())\n",
    "print(\"Test numerical columns after filling:\", test[numerical_cols].isnull().sum())\n",
    "\n",
    "# 3. FILL categorical columns -> with 'Unknown'\n",
    "for column in categorical_cols:\n",
    "    train[column] = train[column].fillna('Unknown')\n",
    "    test[column] = test[column].fillna('Unknown')   \n",
    "# Quick check: filled categorical columns\n",
    "print(\"Train categorical columns after filling:\", train[categorical_cols].isnull().sum())\n",
    "print(\"Test categorical columns after filling:\", test[categorical_cols].isnull().sum())\n",
    "\n",
    "#4. FILL remaining missing values -> with 'Unknown'\n",
    "train.fillna('Unknown', inplace=True)\n",
    "test.fillna('Unknown', inplace=True)\n",
    "# Last check: filled remaining missing values\n",
    "print(\"Remaining missing values in train:\", train.isnull().sum().sum())\n",
    "print(\"Remaining missing values in test:\", test.isnull().sum().sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4888f1c0",
   "metadata": {},
   "source": [
    "---\n",
    "# 5. Checking database Consistency\n",
    "\n",
    "Before training a model, we need to make sure that the train and test datasets have the same structure.\n",
    "\n",
    "We need to take into account that the train set contains the target column 'value_eur', while the test set does not because we still need to predict it. So we temporarily drop this column from the train set before comparing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea4b94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = train.drop(columns=['value_eur'])\n",
    "\n",
    "# Checking if train and test datasets have the same columns\n",
    "train_columns = set(train_features.columns)\n",
    "test_columns = set(test.columns)\n",
    "\n",
    "if train_columns != test_columns:\n",
    "    print(\"Mismatch in columns between train and test datasets:\")\n",
    "    print(\"Columns in train but not in test:\", train_columns - test_columns)\n",
    "    print(\"Columns in test but not in train:\", test_columns - train_columns)\n",
    "else:\n",
    "    print(\"Train and test datasets have the same columns.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56eb65bd",
   "metadata": {},
   "source": [
    "---\n",
    "# 6. Final Checks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba54a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for unexpected missing values\n",
    "missing_train = train.isnull().sum()[train.isnull().sum() > 0]\n",
    "if missing_train.empty:\n",
    "    print(\"No unexpected missing values in train dataset. \")\n",
    "else:\n",
    "    print(missing_train)\n",
    "\n",
    "missing_test = test.isnull().sum()[test.isnull().sum() > 0]\n",
    "if missing_test.empty:\n",
    "    print(\"No unexpected missing values in test dataset. \")\n",
    "else:\n",
    "    print(missing_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd965097",
   "metadata": {},
   "source": [
    "---\n",
    "# 7. Conclusion\n",
    "This data cleaning process helped us to make sure that the datasets are consistent and ready for modelling. \n",
    "\n",
    "We addressed missing values by dropping irrelevant columns, properly filling missing values , and verifying that the train and test datasets have matching structures. \n",
    "\n",
    "With the data now cleaned and organized, we're ready to build and evaluate predictive models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
